从本周开始我们进入人工智能核心技术模块，本周我会集中讲解经典的
搜索核心算法，今天先来介绍 TF-IDF 算法。在信息检索
（Information Retrieval）、文本挖掘（Text Mining）
以及自然语言处理（Natural Language Processing）领域，
TF-IDF 算法都可以说是鼎鼎有名。虽然在这些领域中，
目前也出现了不少以深度学习为基础的新的文本表达和算分（Weighting）
方法，但是 TF-IDF 作为一个最基础的方法，
依然在很多应用中发挥着不可替代的作用。
了解和掌握 TF-IDF 算法对初学者大有裨益，
能够帮助初学者更快地理解其它更加深入、复杂的文本挖掘算法和模型。
今天我就来谈谈 TF-IDF 的历史、算法本身的细节以及基于 TF-IDF 
的几个变种算法。

## 1. TF算法详解

要理解 TF-IDF 算法，第一个步骤是理解 TF-IDF 的应用背景。
TF-IDF 来源于一个最经典、也是最古老的信息检索模型，即“向量空间模型”（Vector Space Model）。

简单来说，向量空间模型就是希望把查询关键字和文档都表达成向量，然后利用向量之间的运算来进一步表达向量间的关系。比如，一个比较常用的运算就是计算查询关键字所对应的向量和文档所对应的向量之间的“相关度”

一般情况下，向量空间模型是根据词库大小决定向量的维度的，可以见如下：

```
[
[0,1,0,0,0,0,1,1,2,3,2,1]
]

代表doc1中各个字的出现次数，0代表出现0次，所以维度代表词库的大小。

```
根据词频的含义，可以理解为一句话中某个词出现频率越高说明这个词越是关键的。

但是特殊情况，像的，什么，啊，这种停止词在大部分的句子里都会出现，那么就像需要IDF的在处理。


## IDF 算法详解

IDF，也就是“逆文档频率”（Inverse Document Frequency），就在这样的情况下应运而生。这里面的思路其实很简单，那就是我们需要去“惩罚”（Penalize）那些出现在太多文档中的单词。

也就是说，真正携带“相关”信息的单词仅仅出现在相对比较少，有时候可能是极少数的文档里。这个信息，很容易用“文档频率”来计算，也就是，有多少文档涵盖了这个单词。很明显，如果有太多文档都涵盖了某个单词，这个单词也就越不重要，或者说是这个单词就越没有信息量。因此，我们需要对 TF 的值进行修正，而 IDF 的想法是用 DF 的倒数来进行修正。倒数的应用正好表达了这样的思想，DF 值越大越不重要。


##TF-IDF 算法变种

首先，很多人注意到 TF 的值在原始的定义中没有任何上限。虽然我们一般认为一个文档包含查询关键词多次相对来说表达了某种相关度，但这样的关系很难说是线性的。拿我们刚才举过的关于“Car Insurance”的例子来说，文档 A 可能包含“Car”这个词 100 次，而文档 B 可能包含 200 次，是不是说文档 B 的相关度就是文档 A 的 2 倍呢？其实，很多人意识到，超过了某个阈值之后，这个 TF 也就没那么有区分度了。用 Log，也就是对数函数，对 TF 进行变换，就是一个不让 TF 线性增长的技巧。具体来说，人们常常用 1+Log(TF) 这个值来代替原来的 TF 取值。在这样新的计算下，假设“Car”出现一次，新的值是 1，出现 100 次，新的值是 5.6，而出现 200 次，新的值是 6.3。很明显，这样的计算保持了一个平衡，既有区分度，但也不至于完全线性增长。另外一个关于 TF 的观察则是，经典的计算并没有考虑“长文档”和“短文档”的区别。一个文档 A 有 3,000 个单词，一个文档 B 有 250 个单词，很明显，即便“Car”在这两个文档中都同样出现过 20 次，也不能说这两个文档都同等相关。对 TF 进行“标准化”（Normalization），特别是根据文档的最大 TF 值进行的标准化，成了另外一个比较常用的技巧。第三个常用的技巧，也是利用了对数函数进行变换的，是对 IDF 进行处理。相对于直接使用 IDF 来作为“惩罚因素”，我们可以使用 N+1 然后除以 DF 作为一个新的 DF 的倒数，并且再在这个基础上通过一个对数变化。这里的 N 是所有文档的总数。这样做的好处就是，第一，使用了文档总数来做标准化，很类似上面提到的标准化的思路；第二，利用对数来达到非线性增长的目的。还有一个重要的 TF-IDF 变种，则是对查询关键字向量，以及文档向量进行标准化，使得这些向量能够不受向量里有效元素多少的影响，也就是不同的文档可能有不同的长度。在线性代数里，可以把向量都标准化为一个单位向量的长度。这个时候再进行点积运算，就相当于在原来的向量上进行余弦相似度的运算。所以，另外一个角度利用这个规则就是直接在多数时候进行余弦相似度运算，以代替点积运算。